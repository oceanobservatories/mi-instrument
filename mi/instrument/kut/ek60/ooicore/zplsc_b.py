#!/usr/bin/env python

"""
@package mi.dataset.parser.zplsc_b
@file marine-integrations/mi/dataset/parser/zplsc_b.py
@author Ronald Ronquillo & Richard Han
@brief Parser for the zplsc_b dataset driver

This file contains code for the zplsc_b parser to produce data particles and echogram plots.

The Simrad EK60 scientific echo sounder supports the *.raw file format.
The *.raw file may contain one or more of the following datagram types:
Configuration, NMEA, Annotation, Sample.

Every *.raw file begins with a configuration datagram. A second configuration datagram
within the file is illegal. The data content of the Configuration datagram of an already
existing file cannot be altered from the EK60. NMEA, Annotation and Sample datagrams
constitute the remaining file content. These datagrams are written to the *.raw file in the
order that they are generated by the EK60. Note: Strictly sequential time tags are not guaranteed.

A data particle is produced from metadata contained in the first ping of the series.
The metadata and echogram plots are extracted from the Sample datagram portion of the *.raw file.


Release notes:

Initial Release
"""

import re
import os
import numpy
from multiprocessing import Process
from datetime import datetime
from struct import unpack_from
from collections import defaultdict

from mi.core.common import BaseEnum
from mi.core.exceptions import InstrumentDataException
from mi.core.instrument.data_particle import DataParticle
from mi.core.log import get_logger

from mi.instrument.kut.ek60.ooicore.zplsc_echogram import SAMPLE_MATCHER, LENGTH_SIZE, DATAGRAM_HEADER_SIZE, \
    CONFIG_HEADER_SIZE, CONFIG_TRANSDUCER_SIZE, \
    generate_plots, read_datagram_header, read_config_header

log = get_logger()
__author__ = 'Ronald Ronquillo'
__license__ = 'Apache 2.0'


class ZplscBParticleKey(BaseEnum):
    """
    Class that defines fields that need to be extracted from the data
    """
    FILE_TIME = "zplsc_timestamp"               # raw file timestamp
    ECHOGRAM_PATH = "zplsc_echogram"                      # output echogram plot .png/s path and filename
    CHANNEL = "zplsc_channel"
    TRANSDUCER_DEPTH = "zplsc_transducer_depth"  # five digit floating point number (%.5f, in meters)
    FREQUENCY = "zplsc_frequency"               # six digit fixed point integer (in Hz)
    TRANSMIT_POWER = "zplsc_transmit_power"     # three digit fixed point integer (in Watts)
    PULSE_LENGTH = "zplsc_pulse_length"         # six digit floating point number (%.6f, in seconds)
    BANDWIDTH = "zplsc_bandwidth"               # five digit floating point number (%.5f in Hz)
    SAMPLE_INTERVAL = "zplsc_sample_interval"   # six digit floating point number (%.6f, in seconds)
    SOUND_VELOCITY = "zplsc_sound_velocity"     # five digit floating point number (%.5f, in m/s)
    ABSORPTION_COEF = "zplsc_absorption_coeff"  # four digit floating point number (%.4f, dB/m)
    TEMPERATURE = "zplsc_temperature"           # three digit floating point number (%.3f, in degC)


# The following is used for _build_parsed_values() and defined as below:
# (parameter name, encoding function)
METADATA_ENCODING_RULES = [
    (ZplscBParticleKey.FILE_TIME, str),
    (ZplscBParticleKey.ECHOGRAM_PATH, lambda x: [str(y) for y in x]),
    (ZplscBParticleKey.CHANNEL, lambda x: [int(y) for y in x]),
    (ZplscBParticleKey.TRANSDUCER_DEPTH, lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.FREQUENCY, lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.TRANSMIT_POWER, lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.PULSE_LENGTH, lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.BANDWIDTH, lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.SAMPLE_INTERVAL, lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.SOUND_VELOCITY, lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.ABSORPTION_COEF, lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.TEMPERATURE, lambda x: [float(y) for y in x])
]

# Numpy data type object for unpacking the Sample datagram including the header from binary *.raw
sample_dtype = numpy.dtype([('length1', 'i4'),  # 4 byte int (long)
                            # DatagramHeader
                            ('datagram_type', 'a4'),  # 4 byte string
                            ('low_date_time', 'i4'),  # 4 byte int (long)
                            ('high_date_time', 'i4'),  # 4 byte int (long)
                            # SampleDatagram
                            ('channel_number', 'i2'),  # 2 byte int (short)
                            ('mode', 'i2'),  # 2 byte int (short)
                            ('transducer_depth', 'f4'),  # 4 byte float
                            ('frequency', 'f4'),  # 4 byte float
                            ('transmit_power', 'f4'),  # 4 byte float
                            ('pulse_length', 'f4'),  # 4 byte float
                            ('bandwidth', 'f4'),  # 4 byte float
                            ('sample_interval', 'f4'),  # 4 byte float
                            ('sound_velocity', 'f4'),  # 4 byte float
                            ('absorption_coefficient', 'f4'),  # 4 byte float
                            ('heave', 'f4'),  # 4 byte float
                            ('roll', 'f4'),  # 4 byte float
                            ('pitch', 'f4'),  # 4 byte float
                            ('temperature', 'f4'),  # 4 byte float
                            ('trawl_upper_depth_valid', 'i2'),  # 2 byte int (short)
                            ('trawl_opening_valid', 'i2'),  # 2 byte int (short)
                            ('trawl_upper_depth', 'f4'),  # 4 byte float
                            ('trawl_opening', 'f4'),  # 4 byte float
                            ('offset', 'i4'),  # 4 byte int (long)
                            ('count', 'i4')])                     # 4 byte int (long)
sample_dtype = sample_dtype.newbyteorder('<')

power_dtype = numpy.dtype([('power_data', '<i2')])     # 2 byte int (short)

angle_dtype = numpy.dtype([('athwart', '<i1'), ('along', '<i1')])     # 1 byte ints

GET_CONFIG_TRANSDUCER = False   # Optional data flag: not currently used
BLOCK_SIZE = 1024*4             # Block size read in from binary file to search for token

# ZPLSC EK 60 *.raw filename timestamp format
# ei. OOI-D20141211-T214622.raw
TIMESTAMP_FORMAT = "%Y%m%d%H%M%S"

# Regex to extract the timestamp from the *.raw filename (path/to/OOI-DYYYYmmdd-THHMMSS.raw)
FILE_NAME_REGEX = r'(?P<Refdes>\S*)_*OOI-D(?P<Date>\d{8})-T(?P<Time>\d{6})\.raw'
FILE_NAME_MATCHER = re.compile(FILE_NAME_REGEX)

windows_ntp_diff = (datetime(1900, 1, 1) - datetime(1601, 1, 1)).total_seconds()


class DataParticleType(BaseEnum):
    """
    Class that defines the data particles generated from the zplsc_b data
    """
    METADATA = 'zplsc_metadata'  # instrument data particle


class ZplscBInstrumentDataParticle(DataParticle):
    """
    Class for generating the zplsc_b_instrument data particle.
    """

    _data_particle_type = DataParticleType.METADATA

    def _build_parsed_values(self):
        """
        Build parsed values for Instrument Data Particle.
        """

        # Generate a particle by calling encode_value for each entry
        # in the Instrument Particle Mapping table,
        # where each entry is a tuple containing the particle field name
        # and a function to use for data conversion.

        return [self._encode_value(name, self.raw_data[name], function)
                for name, function in METADATA_ENCODING_RULES]


def parse_echogram_file(input_file_path, output_file_path=None):
    """
    Parse the *.raw file.
    @param input_file_path absolute path/name to file to be parsed
    @param output_file_path optional path to directory to write output
    If omitted outputs are written to path of input file
    """

    try:
        input_file = open(input_file_path, 'rb')
    except IOError as e:
        log.error('Could not open Raw Echogram file: %r %r', input_file_path, e)
        raise

    # Extract the file time from the file name
    input_file_name = input_file.name
    file_path, filename = os.path.split(input_file_name)

    if output_file_path is None:
        output_file_path = file_path

    # tuple contains the string before the '.', the '.', and the 'raw' string
    outfile = filename.rpartition('.')[0]

    match = FILE_NAME_MATCHER.match(input_file_name)
    if match:
        file_time = match.group('Date') + match.group('Time')
    else:
        # Files retrieved from the instrument should always match the timestamp naming convention
        error_message = \
            "Unable to extract file time from input file name: %s. Expected format *-DYYYYmmdd-THHMMSS.raw" \
            % input_file_name
        log.error(error_message)
        raise InstrumentDataException(error_message)

    # Read binary file a block at a time
    raw = input_file.read(BLOCK_SIZE)

    # Set starting byte
    byte_cnt = 0

    # Read the configuration datagram, output at the beginning of the file
    length1, = unpack_from('<l', raw)
    byte_cnt += LENGTH_SIZE

    # Configuration datagram header
    read_datagram_header(raw[byte_cnt:byte_cnt+DATAGRAM_HEADER_SIZE])
    byte_cnt += DATAGRAM_HEADER_SIZE

    # Configuration: header
    config_header = read_config_header(raw[byte_cnt:byte_cnt+CONFIG_HEADER_SIZE])
    byte_cnt += CONFIG_HEADER_SIZE

    transducer_count = config_header['transducer_count']

    byte_cnt += CONFIG_TRANSDUCER_SIZE * transducer_count

    # Compare length1 (from beginning of datagram) to length2 (from the end of datagram) to
    # the actual number of bytes read. A mismatch can indicate an invalid, corrupt, misaligned,
    # or missing configuration datagram or a reverse byte order binary data file.
    # A bad/missing configuration datagram header is a significant error.
    length2, = unpack_from('<l', raw, byte_cnt)
    if not (length1 == length2 == byte_cnt-LENGTH_SIZE):
        raise InstrumentDataException(
            "Length of configuration datagram and number of bytes read do not match: length1: %s"
            ", length2: %s, byte_cnt: %s. Possible file corruption or format incompatibility." %
            (length1, length2, byte_cnt+LENGTH_SIZE))

    first_ping_metadata = defaultdict(list)
    trans_keys = range(1, transducer_count+1)
    trans_array = dict((key, []) for key in trans_keys)         # transducer power data
    trans_array_time = dict((key, []) for key in trans_keys)    # transducer time data
    td_f = dict.fromkeys(trans_keys)                            # transducer frequency
    td_dr = dict.fromkeys(trans_keys)                           # transducer depth measurement

    position = 0
    particle_data = (None, None)

    while raw:
        # We only care for the Sample datagrams, skip over all the other datagrams
        match = SAMPLE_MATCHER.search(raw)

        if not match:
            # Read in the next block w/ a token sized overlap
            input_file.seek(input_file.tell() - 4)
            raw = input_file.read(BLOCK_SIZE)

            # The last 4 bytes is just the length2 of the last datagram
            if len(raw) <= 4:
                break

        # Offset by size of length value
        match_start = match.start() - LENGTH_SIZE

        # Seek to the position of the length data before the token to read into numpy array
        input_file.seek(position + match_start)

        # Read and unpack the Sample Datagram into numpy array
        sample_data = numpy.fromfile(input_file, dtype=sample_dtype, count=1)
        channel = sample_data['channel_number'][0]

        # Check for a valid channel number that is within the number of transducers config
        # to prevent incorrectly indexing into the dictionaries.
        # An out of bounds channel number can indicate invalid, corrupt,
        # or misaligned datagram or a reverse byte order binary data file.
        # Log warning and continue to try and process the rest of the file.
        if channel < 0 or channel > transducer_count:
            log.warn("Invalid channel: %s for transducer count: %s."
                     "Possible file corruption or format incompatibility.", channel, transducer_count)

            # Need current position in file to increment for next regex search offset
            position = input_file.tell()

            # Read the next block for regex search
            raw = input_file.read(BLOCK_SIZE)
            continue

        # Convert high and low bytes to internal time
        internal_time = (sample_data['high_date_time'][0] << 32) + sample_data['low_date_time'][0]
        # Note: Strictly sequential time tags are not guaranteed.
        trans_array_time[channel].append(internal_time)

        # Gather metadata once per transducer channel number
        if not trans_array[channel]:
            outfile += '_' + str(int(sample_data['frequency'])/1000) + 'k.png'
            file_path = os.path.join(output_file_path, outfile)

            first_ping_metadata[ZplscBParticleKey.FILE_TIME] = file_time
            first_ping_metadata[ZplscBParticleKey.ECHOGRAM_PATH].append(file_path)
            first_ping_metadata[ZplscBParticleKey.CHANNEL].append(channel)
            first_ping_metadata[ZplscBParticleKey.TRANSDUCER_DEPTH].append(sample_data['transducer_depth'][0])
            first_ping_metadata[ZplscBParticleKey.FREQUENCY].append(sample_data['frequency'][0])
            first_ping_metadata[ZplscBParticleKey.TRANSMIT_POWER].append(sample_data['transmit_power'][0])
            first_ping_metadata[ZplscBParticleKey.PULSE_LENGTH].append(sample_data['pulse_length'][0])
            first_ping_metadata[ZplscBParticleKey.BANDWIDTH].append(sample_data['bandwidth'][0])
            first_ping_metadata[ZplscBParticleKey.SAMPLE_INTERVAL].append(sample_data['sample_interval'][0])
            first_ping_metadata[ZplscBParticleKey.SOUND_VELOCITY].append(sample_data['sound_velocity'][0])
            first_ping_metadata[ZplscBParticleKey.ABSORPTION_COEF].append(sample_data['absorption_coefficient'][0])
            first_ping_metadata[ZplscBParticleKey.TEMPERATURE].append(sample_data['temperature'][0])

            # Make only one particle for the first ping series containing data for all channels
            if channel == config_header['transducer_count']:
                # Convert from Windows time to NTP time.
                time_stamp = internal_time / 10000.0 - windows_ntp_diff

                # Put the metadata and timestamp in a tuple to return to calling method for creation
                # of a particle

                particle_data = (first_ping_metadata, time_stamp)

            # Extract various calibration parameters used for generating echogram plot
            # This data doesn't change so extract it once per channel
            td_f[channel] = sample_data['frequency'][0]
            td_dr[channel] = sample_data['sound_velocity'][0] * sample_data['sample_interval'][0] / 2

        count = sample_data['count'][0]

        # Extract array of power data
        power_data = numpy.fromfile(input_file, dtype=power_dtype, count=count)

        # Decompress power data to dB
        trans_array[channel].append(power_data['power_data'] * 10. * numpy.log10(2) / 256.)

        # Read the athwartship and alongship angle measurements
        if sample_data['mode'][0] > 1:
            numpy.fromfile(input_file, dtype=angle_dtype, count=count)

        # Read and compare length1 (from beginning of datagram) to length2
        # (from the end of datagram). A mismatch can indicate an invalid, corrupt,
        # or misaligned datagram or a reverse byte order binary data file.
        # Log warning and continue to try and process the rest of the file.
        len_dtype = numpy.dtype([('length2', '<i4')])     # 4 byte int (long)
        length2_data = numpy.fromfile(input_file, dtype=len_dtype, count=1)
        if not (sample_data['length1'][0] == length2_data['length2'][0]):
            log.warn("Mismatching beginning and end length values in sample datagram: length1"
                     ": %s, length2: %s. Possible file corruption or format incompatibility.",
                     sample_data['length1'][0], length2_data['length2'][0])

        # Need current position in file to increment for next regex search offset
        position = input_file.tell()

        # Read the next block for regex search
        raw = input_file.read(BLOCK_SIZE)

    # Driver spends most of the time plotting,
    # this can take longer for more transducers so lets break out the work
    processes = []

    for channel in td_f.iterkeys():
        try:
            process = Process(target=generate_echogram_plot,
                              args=(trans_array_time[channel], trans_array[channel],
                                    td_f[channel], td_dr[channel], channel,
                                    os.path.join(
                                        output_file_path,
                                        first_ping_metadata[ZplscBParticleKey.ECHOGRAM_PATH][channel - 1])))
            process.start()
            processes.append(process)

        except Exception, e:
            log.error("Error: Unable to start process: %s", e)

    for p in processes:
        p.join()

    return particle_data


def generate_echogram_plot(trans_array_time, trans_array, td_f, td_dr, channel, filename):
    # Generate echogram plots with sample data collected for each channel
    # Transpose array data so the sample power data is on the y-axis
    trans_array = numpy.transpose(trans_array)

    generate_plots(trans_array, trans_array_time, td_f, td_dr,
                   "Transducer # " + str(channel) + ": ", filename)
